# Data Lake using Spark

The purpose of the project is to build a Data Lake using Spark optimized for queries on songplays analysis. The data source is log files and event files in a S3 bucket. These files will be processed using Spark and saved back in a S3 bucket into tables following a Star Schema and stored in [parquet file format](https://spark.apache.org/docs/latest/sql-data-sources-parquet.html).

## Data source
- **Songs dataset:** The first dataset is a subset of real data from the [Million Song Dataset](http://millionsongdataset.com/). Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID. An entry of this dataset looks like:

```json
{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}
```

- **Log dataset:** The second dataset consists of log files in JSON format generated by an [event simulator](https://github.com/Interana/eventsim) based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.

```json
{"artist":"Des'ree","auth":"Logged In","firstName":"Kaylee","gender":"F","itemInSession":1,"lastName":"Summers","length":246.30812,"level":"free","location":"Phoenix-Mesa-Scottsdale, AZ","method":"PUT","page":"NextSong","registration":1540344794796.0,"sessionId":139,"song":"You Gotta Be","status":200,"ts":1541106106796,"userAgent":"\"Mozilla\/5.0 (Windows NT 6.1; WOW64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/35.0.1916.153 Safari\/537.36\"","userId":"8"}
```

### Project Structure:

- **template.ipynb:** Perform steps as in etl.py file, used during development.

- **dl.cfg:** Stores AWS credentials

- **etl.py:** Reads data from S3, process using Spark, and writes them back to S3

### How to run

Fill the dl.cfg file and run the following command in a terminal:

```
python etl.py
```